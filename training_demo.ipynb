{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.utils import *\n",
    "from src.nets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load dataset ####\n",
    "train_imgs_color=sio.loadmat('./data/training_images.mat')['ims']\n",
    "train_segs=torch.from_numpy(sio.loadmat('./data/training_segmentations.mat')['segs']).long()\n",
    "\n",
    "# make images gray\n",
    "train_imgs = torch.from_numpy(np.dot(train_imgs_color,[0.299, 0.587, 0.114]))\n",
    "\n",
    "# setting dataset for process\n",
    "img_train = train_imgs.float().unsqueeze(1)/255.0\n",
    "seg_train = train_segs\n",
    "\n",
    "numtrain = img_train.shape[0]\n",
    "img_train = img_train[:numtrain]\n",
    "seg_train = seg_train[:numtrain]\n",
    "\n",
    "print(train_imgs.shape, train_segs.shape)\n",
    "print(img_train.shape, seg_train.shape)\n",
    "\n",
    "# label weight\n",
    "a = torch.bincount(seg_train.contiguous().view(-1))\n",
    "label_weights = torch.sqrt((1/a.float()))/torch.sqrt(1/a.float()).mean()\n",
    "print('label weights:',label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyper parameters####\n",
    "numepochs = 300; \n",
    "learning_rate = 0.001 \n",
    "lambda_weight = 0.001\n",
    "lambda_semantic = 1.0\n",
    "batchsize = 20\n",
    "\n",
    "##### network initialization #####\n",
    "unet = UNet2D(L)\n",
    "unet.apply(init_weights); unet.cuda()\n",
    "regnet1 = RegNet(inch=L*2).cuda()\n",
    "regnet1.apply(init_weights)\n",
    "regnet2 = RegNet(inch=L*2).cuda()\n",
    "regnet2.apply(init_weights)\n",
    "\n",
    "metric = nn.L1Loss()\n",
    "metric_seg = nn.CrossEntropyLoss(weight=label_weights.cuda())\n",
    "optimizer = optim.Adam(list(unet.parameters())+list(regnet1.parameters())+list(regnet2.parameters()),lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,0.97)\n",
    "\n",
    "# start training and validation\n",
    "for epoch in range(numepochs):\n",
    "    idx_epoch = torch.cat((torch.randperm(numtrain).view(-1,1),torch.randperm(numtrain).view(-1,1)),1).view(batchsize,-1,2)\n",
    "\n",
    "    unet.train()\n",
    "    regnet1.train()\n",
    "    regnet2.train()\n",
    "    scheduler.step()\n",
    "\n",
    "    for iter in range(idx_epoch.shape[1]):\n",
    "        idx = idx_epoch[:,iter,:]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # image and segmentation\n",
    "        img_aug, label_aug = augmentAffine(img_train[idx].squeeze().cuda(),seg_train[idx].float().cuda())\n",
    "\n",
    "        y_label1 = label_aug[:,0]; y_label2 = label_aug[:,1]  \n",
    "        label_y1 = labelMatrixOneHot(y_label1.cpu(),L)\n",
    "        label_y2 = labelMatrixOneHot(y_label2.cpu(),L)\n",
    "\n",
    "        # train UNet\n",
    "        seg_predict1 = unet(img_aug[:,0:1].cuda())\n",
    "        seg_predict2 = unet(img_aug[:,1:2].cuda()) \n",
    "\n",
    "        # train registration networks\n",
    "        predflow1 = regnet1(torch.cat((seg_predict1,seg_predict2),1))\n",
    "        warped_mov1, estflow1 = BsplineTrafo(seg_predict2,predflow1,19)\n",
    "        predflow2 = regnet2(torch.cat((seg_predict1,warped_mov1),1))\n",
    "\n",
    "        # segmentation loss (semantic guidance)\n",
    "        semanticloss = 0.5*metric_seg(seg_predict1,y_label1[:,::2,::2].long().cuda())+0.5*metric_seg(seg_predict2,y_label2[:,::2,::2].long().cuda())\n",
    "        warped_mov2, estflow2 = BsplineTrafo(warped_mov1.float().cuda(),predflow2,11)\n",
    "\n",
    "        # deformation field is sum of estimated fields from two networks            \n",
    "        def_x2 = F.interpolate(estflow1+estflow2,scale_factor=2,mode='bilinear')\n",
    "        warped_seg = warpImage(label_y2.float().cuda(),def_x2)\n",
    "\n",
    "        # deformation loss\n",
    "        deformloss = torch.mean((warped_seg-label_y1.float().cuda()).abs()*label_weights.view(1,L,1,1).cuda())\n",
    "\n",
    "        # regularization loss\n",
    "        dx = def_x2[:,0:1,:,:];         dy = def_x2[:,1:2,:,:]\n",
    "        dx_smooth = F.avg_pool2d(F.avg_pool2d(dx,5,padding=2,stride=1),5,padding=2,stride=1)\n",
    "        dy_smooth = F.avg_pool2d(F.avg_pool2d(dy,5,padding=2,stride=1),5,padding=2,stride=1)\n",
    "        regloss = torch.norm(dx-dx_smooth)+torch.norm(dy-dy_smooth)\n",
    "\n",
    "        # total loss\n",
    "        loss = lambda_semantic*semanticloss + deformloss + lambda_weight*regloss\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()       \n",
    "\n",
    "        J = torch.std(jacobian_det(def_x2.data.cpu()))\n",
    "        Jnegativ = (jacobian_det(def_x2.data.cpu())<0).float().mean()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
